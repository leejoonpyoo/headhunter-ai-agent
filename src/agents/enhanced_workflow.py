"""ê³ ë„í™”ëœ í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ LangGraph ì›Œí¬í”Œë¡œìš° - Customer Support Agent ìŠ¤íƒ€ì¼"""

import os
from typing import List, Dict, Any, TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_upstage import ChatUpstage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, create_react_agent
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command
from dotenv import load_dotenv

# ë„êµ¬ë“¤ ì„í¬íŠ¸
from ..tools.candidate_tools import (
    search_candidates_by_skills,
    search_candidates_by_location,
    search_candidates_by_salary_range,
    search_candidates_by_work_type,
    search_candidates_by_industry,
    search_candidates_by_availability,
    get_candidate_details,
    complex_candidate_search,
    get_candidate_statistics
)
from ..tools.market_tools import (
    search_tech_information,
    search_market_trends,
    search_industry_analysis,
    search_salary_information,
    general_knowledge_search,
    compare_technologies,
    get_knowledge_base_stats
)
from ..tools.web_search_tools import (
    web_search_latest_trends,
    search_job_postings,
    search_company_information,
    search_salary_benchmarks,
    search_tech_news,
    search_startup_funding_news
)

load_dotenv()

class HeadhunterAgentState(TypedDict):
    """í—¤ë“œí—Œí„° ì—ì´ì „íŠ¸ì˜ ìƒíƒœ ì •ì˜"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    customer_query: str
    query_type: str  # "candidate_search", "market_analysis", "web_research", "general"
    search_context: Dict[str, Any]
    results: Dict[str, Any]
    next_action: str
    needs_clarification: bool

class EnhancedHeadhunterWorkflow:
    """ê³ ë„í™”ëœ í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°"""

    def __init__(self):
        # LLM ì´ˆê¸°í™”
        self.llm = ChatUpstage(
            model="solar-pro2",
            temperature=0
        )

        # ë„êµ¬ë“¤ ì„¤ì •
        self.candidate_tools = [
            search_candidates_by_skills,
            search_candidates_by_location,
            search_candidates_by_salary_range,
            search_candidates_by_work_type,
            search_candidates_by_industry,
            search_candidates_by_availability,
            get_candidate_details,
            complex_candidate_search,
            get_candidate_statistics
        ]

        self.market_tools = [
            search_tech_information,
            search_market_trends,
            search_industry_analysis,
            search_salary_information,
            general_knowledge_search,
            compare_technologies,
            get_knowledge_base_stats
        ]

        self.web_tools = [
            web_search_latest_trends,
            search_job_postings,
            search_company_information,
            search_salary_benchmarks,
            search_tech_news,
            search_startup_funding_news
        ]

        # ëª¨ë“  ë„êµ¬ ê²°í•©
        self.all_tools = self.candidate_tools + self.market_tools + self.web_tools

        # LLMì— ë„êµ¬ ë°”ì¸ë”©
        self.llm_with_tools = self.llm.bind_tools(self.all_tools)

        # ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
        self.workflow = self._build_enhanced_workflow()

    def _build_enhanced_workflow(self) -> StateGraph:
        """ê³ ë„í™”ëœ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¶•"""
        workflow = StateGraph(HeadhunterAgentState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("initial_analysis", self._initial_analysis)
        workflow.add_node("query_classifier", self._classify_query)
        workflow.add_node("context_enricher", self._enrich_context)
        workflow.add_node("candidate_specialist", self._candidate_specialist)
        workflow.add_node("market_specialist", self._market_specialist)
        workflow.add_node("web_researcher", self._web_researcher)
        workflow.add_node("tools", ToolNode(self.all_tools))
        workflow.add_node("result_synthesizer", self._synthesize_results)
        workflow.add_node("quality_checker", self._quality_check)
        workflow.add_node("response_formatter", self._format_response)

        # ì‹œì‘ì  ì„¤ì •
        workflow.set_entry_point("initial_analysis")

        # ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì •ì˜
        workflow.add_edge("initial_analysis", "query_classifier")
        workflow.add_edge("query_classifier", "context_enricher")

        # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "context_enricher",
            self._route_to_specialist,
            {
                "candidate": "candidate_specialist",
                "market": "market_specialist",
                "web": "web_researcher",
                "tools": "tools"
            }
        )

        # ì „ë¬¸ê°€ ë…¸ë“œë“¤ì—ì„œ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
        for specialist in ["candidate_specialist", "market_specialist", "web_researcher"]:
            workflow.add_conditional_edges(
                specialist,
                self._should_use_tools,
                {
                    "tools": "tools",
                    "synthesize": "result_synthesizer"
                }
            )

        # ë„êµ¬ ì‚¬ìš© í›„ ê²°ê³¼ í•©ì„±
        workflow.add_edge("tools", "result_synthesizer")

        # ê²°ê³¼ í•©ì„± í›„ í’ˆì§ˆ ê²€ì‚¬
        workflow.add_edge("result_synthesizer", "quality_checker")

        # í’ˆì§ˆ ê²€ì‚¬ í›„ ì‘ë‹µ í¬ë§·íŒ… ë˜ëŠ” ì¬ì²˜ë¦¬
        workflow.add_conditional_edges(
            "quality_checker",
            self._quality_decision,
            {
                "format": "response_formatter",
                "retry": "context_enricher"
            }
        )

        # ì‘ë‹µ í¬ë§·íŒ… í›„ ì¢…ë£Œ
        workflow.add_edge("response_formatter", END)

        return workflow

    def _initial_analysis(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì´ˆê¸° ë¶„ì„ - ì‚¬ìš©ì ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        last_message = state["messages"][-1]
        user_query = last_message.content

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        system_message = SystemMessage(content="""
        ë‹¹ì‹ ì€ ì „ë¬¸ í—¤ë“œí—Œí„° AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

        1. ì¸ì¬ ê²€ìƒ‰ ë° ë§¤ì¹­
        2. ì‹œì¥ ë™í–¥ ë¶„ì„
        3. ê¸°ìˆ  íŠ¸ë Œë“œ ì—°êµ¬
        4. ì±„ìš© ì‹œì¥ ì •ë³´ ì œê³µ

        í•­ìƒ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)

        state["messages"] = [system_message] + state["messages"]
        state["customer_query"] = user_query
        state["search_context"] = {}
        state["results"] = {}
        state["needs_clarification"] = False

        return state

    def _classify_query(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì¿¼ë¦¬ ë¶„ë¥˜ - ê³ ë„í™”ëœ ë¶„ë¥˜ ë¡œì§"""
        user_query = state["customer_query"]

        classification_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ì™€ ì„¸ë¶€ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”:

        ì‚¬ìš©ì ì§ˆë¬¸: {user_query}

        ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬:
        1. candidate_search - ì¸ì¬ ê²€ìƒ‰, í›„ë³´ì ì •ë³´, ìŠ¤í‚¬ ë§¤ì¹­, ì¸ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
        2. market_analysis - ì‹œì¥ íŠ¸ë Œë“œ, ì‚°ì—… ë¶„ì„, ê¸°ìˆ  ì •ë³´, ê¸‰ì—¬ ë¶„ì„ (ë‚´ë¶€ ì§€ì‹ ê¸°ë°˜)
        3. web_research - ìµœì‹  ë‰´ìŠ¤, ì±„ìš©ê³µê³ , íšŒì‚¬ ì •ë³´, ì‹¤ì‹œê°„ íŠ¸ë Œë“œ (ì›¹ ê²€ìƒ‰ í•„ìš”)
        4. general - ë³µí•©ì  ì§ˆë¬¸, ìƒë‹´, ì¼ë°˜ì ì¸ í—¤ë“œí—ŒíŒ… ì¡°ì–¸

        ì‘ë‹µ í˜•ì‹:
        ì¹´í…Œê³ ë¦¬: [category]
        ì˜ë„: [êµ¬ì²´ì ì¸ ì˜ë„ ì„¤ëª…]
        í‚¤ì›Œë“œ: [í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œ]
        """

        response = self.llm.invoke([HumanMessage(content=classification_prompt)])

        # ì‘ë‹µ íŒŒì‹± (ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§)
        response_text = response.content.lower()

        if "candidate" in response_text:
            query_type = "candidate_search"
        elif "market" in response_text:
            query_type = "market_analysis"
        elif "web" in response_text:
            query_type = "web_research"
        else:
            query_type = "general"

        state["query_type"] = query_type
        state["messages"].append(response)

        return state

    def _enrich_context(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì»¨í…ìŠ¤íŠ¸ ê°•í™” - ì¿¼ë¦¬ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ"""
        user_query = state["customer_query"]
        query_type = state["query_type"]

        context_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ë§¤ê°œë³€ìˆ˜ì™€ ì¡°ê±´ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

        ì§ˆë¬¸: {user_query}
        ë¶„ë¥˜: {query_type}

        ì¶”ì¶œí•  ì •ë³´:
        - ê¸°ìˆ  ìŠ¤í‚¬ (ì˜ˆ: Python, React, AWS)
        - ì§€ì—­ (ì˜ˆ: ì„œìš¸, ê°•ë‚¨êµ¬)
        - ê²½ë ¥ ë…„ìˆ˜ (ì˜ˆ: 3ë…„ ì´ìƒ)
        - ê¸‰ì—¬ ë²”ìœ„ (ì˜ˆ: 7000-10000ë§Œì›)
        - ì‚°ì—… ë¶„ì•¼ (ì˜ˆ: Fintech, AI/ML)
        - ê·¼ë¬´ í˜•íƒœ (ì˜ˆ: ì›ê²©, í•˜ì´ë¸Œë¦¬ë“œ)
        - ê¸°íƒ€ ì¡°ê±´

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """

        response = self.llm.invoke([HumanMessage(content=context_prompt)])

        # ì‹¤ì œë¡œëŠ” JSON íŒŒì‹±ì„ í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”
        state["search_context"] = {
            "extracted_info": response.content,
            "query_complexity": "medium"
        }

        return state

    def _route_to_specialist(self, state: HeadhunterAgentState) -> str:
        """ì „ë¬¸ê°€ ë¼ìš°íŒ…"""
        query_type = state.get("query_type", "general")

        routing_map = {
            "candidate_search": "candidate",
            "market_analysis": "market",
            "web_research": "web"
        }

        return routing_map.get(query_type, "tools")

    def _candidate_specialist(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì¸ì¬ ê²€ìƒ‰ ì „ë¬¸ê°€"""
        specialist_prompt = """
        ë‹¹ì‹ ì€ ì¸ì¬ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì¸ì¬ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        - search_candidates_by_skills: ê¸°ìˆ  ìŠ¤í‚¬ ê¸°ë°˜ ê²€ìƒ‰
        - search_candidates_by_location: ì§€ì—­ ê¸°ë°˜ ê²€ìƒ‰
        - search_candidates_by_salary_range: ê¸‰ì—¬ ë²”ìœ„ ê¸°ë°˜ ê²€ìƒ‰
        - complex_candidate_search: ë³µí•© ì¡°ê±´ ê²€ìƒ‰
        - get_candidate_statistics: í†µê³„ ì •ë³´

        ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ë¶„ì„í•˜ê³  ê°€ì¥ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.
        ì—¬ëŸ¬ ì¡°ê±´ì´ ìˆë‹¤ë©´ complex_candidate_searchë¥¼ ìš°ì„  ì‚¬ìš©í•˜ì„¸ìš”.
        """

        user_query = state["customer_query"]
        messages = [HumanMessage(content=specialist_prompt + f"\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}")]

        response = self.llm_with_tools.invoke(messages)
        state["messages"].append(response)

        return state

    def _market_specialist(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€"""
        specialist_prompt = """
        ë‹¹ì‹ ì€ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì‹œì¥ íŠ¸ë Œë“œì™€ ê¸°ìˆ  ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        - search_tech_information: ê¸°ìˆ  ì •ë³´ ê²€ìƒ‰
        - search_market_trends: ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„
        - search_industry_analysis: ì‚°ì—… ë¶„ì„
        - search_salary_information: ê¸‰ì—¬ ì •ë³´
        - compare_technologies: ê¸°ìˆ  ë¹„êµ

        ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ì°¾ì•„ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
        """

        user_query = state["customer_query"]
        messages = [HumanMessage(content=specialist_prompt + f"\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}")]

        response = self.llm_with_tools.invoke(messages)
        state["messages"].append(response)

        return state

    def _web_researcher(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì›¹ ì—°êµ¬ ì „ë¬¸ê°€"""
        specialist_prompt = """
        ë‹¹ì‹ ì€ ì›¹ ì—°êµ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Tavilyë¥¼ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ì„¸ìš”:

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        - web_search_latest_trends: ìµœì‹  íŠ¸ë Œë“œ ê²€ìƒ‰
        - search_job_postings: ì±„ìš©ê³µê³  ê²€ìƒ‰
        - search_company_information: íšŒì‚¬ ì •ë³´ ê²€ìƒ‰
        - search_tech_news: ê¸°ìˆ  ë‰´ìŠ¤ ê²€ìƒ‰
        - search_startup_funding_news: ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ë‰´ìŠ¤

        í•­ìƒ ìµœì‹ ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
        """

        user_query = state["customer_query"]
        messages = [HumanMessage(content=specialist_prompt + f"\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}")]

        response = self.llm_with_tools.invoke(messages)
        state["messages"].append(response)

        return state

    def _should_use_tools(self, state: HeadhunterAgentState) -> str:
        """ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        last_message = state["messages"][-1]

        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools"
        else:
            return "synthesize"

    def _synthesize_results(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ê²°ê³¼ í•©ì„±"""
        synthesis_prompt = """
        ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì¢…í•©ì ì¸ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”:

        ë‹µë³€ ê°€ì´ë“œë¼ì¸:
        1. í•µì‹¬ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ ì •ë¦¬
        2. êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì˜ˆì‹œ í¬í•¨
        3. ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ ì œì‹œ
        4. ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ í†¤ ìœ ì§€
        5. í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì„œë¹„ìŠ¤ ì œì•ˆ

        ì´ì „ ëŒ€í™”ì™€ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        """

        messages = state["messages"] + [HumanMessage(content=synthesis_prompt)]
        response = self.llm.invoke(messages)

        state["messages"].append(response)
        state["results"]["synthesized_response"] = response.content

        return state

    def _quality_check(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """í’ˆì§ˆ ê²€ì‚¬"""
        synthesized_response = state["results"].get("synthesized_response", "")

        quality_criteria = [
            len(synthesized_response) > 50,  # ì¶©ë¶„í•œ ê¸¸ì´
            "êµ¬ì²´ì " in synthesized_response or "ì˜ˆì‹œ" in synthesized_response,  # êµ¬ì²´ì„±
            any(keyword in synthesized_response for keyword in ["ì¶”ì²œ", "ê¶Œì¥", "ì œì•ˆ"])  # ì‹¤í–‰ê°€ëŠ¥ì„±
        ]

        quality_score = sum(quality_criteria) / len(quality_criteria)
        state["results"]["quality_score"] = quality_score

        return state

    def _quality_decision(self, state: HeadhunterAgentState) -> str:
        """í’ˆì§ˆ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
        quality_score = state["results"].get("quality_score", 0)

        if quality_score >= 0.7:
            return "format"
        else:
            return "retry"

    def _format_response(self, state: HeadhunterAgentState) -> HeadhunterAgentState:
        """ì‘ë‹µ í¬ë§·íŒ…"""
        response = state["results"]["synthesized_response"]

        formatted_response = f"""
ğŸ¤– **í—¤ë“œí—Œí„° AI ë¶„ì„ ê²°ê³¼**

{response}

---
ğŸ“Š **ì¶”ê°€ ì„œë¹„ìŠ¤**
- ë” êµ¬ì²´ì ì¸ ì¸ì¬ ê²€ìƒ‰ì´ í•„ìš”í•˜ì‹œë©´ ì„¸ë¶€ ì¡°ê±´ì„ ì•Œë ¤ì£¼ì„¸ìš”
- ì‹œì¥ ë¶„ì„ ìë£Œê°€ ë” í•„ìš”í•˜ì‹œë©´ ìš”ì²­í•´ì£¼ì„¸ìš”
- ì‹¤ì‹œê°„ ì±„ìš© ë™í–¥ì€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì œê³µ ê°€ëŠ¥í•©ë‹ˆë‹¤

ğŸ’¡ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ìƒì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!
        """

        state["messages"].append(AIMessage(content=formatted_response))

        return state

    def get_graph(self):
        """ì»´íŒŒì¼ëœ ê·¸ë˜í”„ ë°˜í™˜"""
        memory = InMemorySaver()
        return self.workflow.compile(checkpointer=memory)

    def create_react_agent_style(self):
        """React Agent ìŠ¤íƒ€ì¼ì˜ ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ ìƒì„±"""
        checkpointer = InMemorySaver()

        agent = create_react_agent(
            model=self.llm,
            tools=self.all_tools,
            prompt="ë‹¹ì‹ ì€ ì „ë¬¸ í—¤ë“œí—Œí„° AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¸ì¬ ê²€ìƒ‰, ì‹œì¥ ë¶„ì„, ì›¹ ì—°êµ¬ë¥¼ í†µí•´ ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ì„¸ìš”.",
            checkpointer=checkpointer
        )

        return agent

# ì „ì—­ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤
_enhanced_workflow_instance = None

def get_enhanced_headhunter_workflow():
    """ê³ ë„í™”ëœ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _enhanced_workflow_instance
    if _enhanced_workflow_instance is None:
        _enhanced_workflow_instance = EnhancedHeadhunterWorkflow()
    return _enhanced_workflow_instance

def get_react_headhunter_agent():
    """React ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ ë°˜í™˜"""
    workflow = get_enhanced_headhunter_workflow()
    return workflow.create_react_agent_style()