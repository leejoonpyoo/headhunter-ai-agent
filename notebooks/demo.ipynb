{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ ë°ëª¨\n",
    "\n",
    "í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•´ë³´ëŠ” ë°ëª¨ ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")\n",
    "print(\"í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    from src.database.repositories import get_candidate_repository\n",
    "    \n",
    "    repo = get_candidate_repository()\n",
    "    stats = repo.get_statistics()\n",
    "    \n",
    "    print(\"âœ… PostgreSQL ì—°ê²° ì„±ê³µ!\")\n",
    "    print(f\"ğŸ“Š ì´ ì¸ì¬ ìˆ˜: {stats['total_candidates']}ëª…\")\n",
    "    print(f\"ğŸ“ ì§€ì—­ ë¶„í¬: {len(stats['location_distribution'])}ê°œ ì§€ì—­\")\n",
    "    print(f\"ğŸ› ï¸ ì¸ê¸° ìŠ¤í‚¬ TOP 5: {[skill['skill'] for skill in stats['top_skills'][:5]]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ docker-compose up -d ëª…ë ¹ì–´ë¡œ PostgreSQLì„ ì‹œì‘í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    from src.vector_store.faiss_store import get_vector_store\n",
    "    \n",
    "    vector_store = get_vector_store()\n",
    "    stats = vector_store.get_stats()\n",
    "    \n",
    "    print(\"âœ… FAISS ë²¡í„° ìŠ¤í† ì–´ ì—°ê²° ì„±ê³µ!\")\n",
    "    print(f\"ğŸ“š ì´ ë¬¸ì„œ ìˆ˜: {stats['total_documents']}ê°œ\")\n",
    "    print(f\"ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:\")\n",
    "    for category, count in stats['categories'].items():\n",
    "        print(f\"   â€¢ {category}: {count}ê°œ\")\n",
    "        \n",
    "    # ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: 'Python ê¸°ìˆ '\")\n",
    "    results = vector_store.search(\"Python ê¸°ìˆ  íŠ¹ì§•\", top_k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"   {i}. {result['metadata'].get('title', 'N/A')} (ì ìˆ˜: {result['score']:.3f})\")\n",
    "        print(f\"      ë‚´ìš©: {result['content'][:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë²¡í„° ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ python setup_project.py ëª…ë ¹ì–´ë¡œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ë„êµ¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\"=== ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸ (PostgreSQL) ===\")\n",
    "\n",
    "try:\n",
    "    from src.tools.candidate_tools import search_candidates_by_skills\n",
    "    \n",
    "    # Python ê°œë°œì ê²€ìƒ‰\n",
    "    result = search_candidates_by_skills.invoke({\"skills\": [\"Python\"], \"min_experience\": 3})\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"âœ… {result['message']}\")\n",
    "        print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {result['count']}ëª…\")\n",
    "        \n",
    "        if result['candidates']:\n",
    "            candidate = result['candidates'][0]\n",
    "            print(f\"ğŸ§‘â€ğŸ’» ì²« ë²ˆì§¸ í›„ë³´ì: {candidate['name']} ({candidate['location']})\")\n",
    "    else:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('message')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\"=== ë¹„ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸ (FAISS Vector DB) ===\")\n",
    "\n",
    "try:\n",
    "    from src.tools.market_tools import search_tech_information\n",
    "    \n",
    "    # Python ê¸°ìˆ  ì •ë³´ ê²€ìƒ‰\n",
    "    result = search_tech_information.invoke({\"technology\": \"Python\", \"top_k\": 2})\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"âœ… {result['message']}\")\n",
    "        print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {result['count']}ê±´\")\n",
    "        \n",
    "        if result['information']:\n",
    "            info = result['information'][0]\n",
    "            print(f\"ğŸ“„ ì²« ë²ˆì§¸ ì •ë³´: {info['metadata'].get('title', 'N/A')}\")\n",
    "            print(f\"ğŸ’¬ ë‚´ìš©: {info['content'][:150]}...\")\n",
    "    else:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('message')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¹„ì •í˜• ë°ì´í„° ë„êµ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸ (Tavily API í‚¤ í•„ìš”)\n",
    "print(\"=== ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸ (Tavily) ===\")\n",
    "\n",
    "try:\n",
    "    from src.tools.web_search_tools import web_search_latest_trends\n",
    "    \n",
    "    # ìµœì‹  ê°œë°œì íŠ¸ë Œë“œ ê²€ìƒ‰\n",
    "    result = web_search_latest_trends.invoke({\n",
    "        \"query\": \"2024 ê°œë°œì íŠ¸ë Œë“œ\", \n",
    "        \"max_results\": 2\n",
    "    })\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"âœ… {result['message']}\")\n",
    "        print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {result['count']}ê±´\")\n",
    "        \n",
    "        if result['results']:\n",
    "            news = result['results'][0]\n",
    "            print(f\"ğŸ“° ì²« ë²ˆì§¸ ë‰´ìŠ¤: {news['title']}\")\n",
    "            print(f\"ğŸ”— URL: {news['url']}\")\n",
    "            print(f\"ğŸ’¬ ë‚´ìš©: {news['content'][:150]}...\")\n",
    "    else:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('message')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ .env íŒŒì¼ì— TAVILY_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\n",
    "print(\"=== AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "try:\n",
    "    from src.agents.workflow import get_headhunter_workflow\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    \n",
    "    # ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”\n",
    "    workflow = get_headhunter_workflow()\n",
    "    graph = workflow.get_graph()\n",
    "    \n",
    "    print(\"âœ… ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "    \n",
    "    # ì›Œí¬í”Œë¡œìš° êµ¬ì¡° í™•ì¸\n",
    "    graph_info = graph.get_graph()\n",
    "    print(f\"ğŸ“Š ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ìˆ˜: {len(graph_info.nodes)}ê°œ\")\n",
    "    print(f\"ğŸ”— ì›Œí¬í”Œë¡œìš° ì—£ì§€ ìˆ˜: {len(graph_info.edges)}ê°œ\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ëª©ë¡:\")\n",
    "    for node in graph_info.nodes:\n",
    "        print(f\"   â€¢ {node}\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ì£¼ì˜: ì‹¤ì œ API í˜¸ì¶œ)\n",
    "    test_query = \"ì•ˆë…•í•˜ì„¸ìš”, í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "    print(f\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_query}\")\n",
    "    print(\"âš ï¸  ì‹¤ì œ API í˜¸ì¶œì„ í”¼í•˜ê¸° ìœ„í•´ êµ¬ì¡° í™•ì¸ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ .env íŒŒì¼ì— UPSTAGE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½\n",
    "print(\"=== ğŸ¯ í—¤ë“œí—Œí„° AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½ ===\")\n",
    "\n",
    "components = {\n",
    "    \"PostgreSQL (ì •í˜• ë°ì´í„°)\": False,\n",
    "    \"FAISS Vector DB (ë¹„ì •í˜• ë°ì´í„°)\": False,\n",
    "    \"AI ì›Œí¬í”Œë¡œìš° (LangGraph)\": False,\n",
    "    \"ì •í˜• ë°ì´í„° ë„êµ¬ë“¤\": False,\n",
    "    \"ë¹„ì •í˜• ë°ì´í„° ë„êµ¬ë“¤\": False,\n",
    "    \"ì›¹ ê²€ìƒ‰ ë„êµ¬ë“¤\": False\n",
    "}\n",
    "\n",
    "# ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸\n",
    "try:\n",
    "    from src.database.repositories import get_candidate_repository\n",
    "    repo = get_candidate_repository()\n",
    "    stats = repo.get_statistics()\n",
    "    if stats['total_candidates'] > 0:\n",
    "        components[\"PostgreSQL (ì •í˜• ë°ì´í„°)\"] = True\n",
    "        components[\"ì •í˜• ë°ì´í„° ë„êµ¬ë“¤\"] = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from src.vector_store.faiss_store import get_vector_store\n",
    "    vector_store = get_vector_store()\n",
    "    stats = vector_store.get_stats()\n",
    "    if stats['total_documents'] > 0:\n",
    "        components[\"FAISS Vector DB (ë¹„ì •í˜• ë°ì´í„°)\"] = True\n",
    "        components[\"ë¹„ì •í˜• ë°ì´í„° ë„êµ¬ë“¤\"] = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from src.agents.workflow import get_headhunter_workflow\n",
    "    workflow = get_headhunter_workflow()\n",
    "    graph = workflow.get_graph()\n",
    "    components[\"AI ì›Œí¬í”Œë¡œìš° (LangGraph)\"] = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "try:\n",
    "    import os\n",
    "    if os.getenv('TAVILY_API_KEY'):\n",
    "        components[\"ì›¹ ê²€ìƒ‰ ë„êµ¬ë“¤\"] = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ìƒíƒœ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ:\")\n",
    "for component, status in components.items():\n",
    "    icon = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"   {icon} {component}\")\n",
    "\n",
    "# í™œì„±í™”ëœ ì»´í¬ë„ŒíŠ¸ ìˆ˜\n",
    "active_count = sum(components.values())\n",
    "total_count = len(components)\n",
    "\n",
    "print(f\"\\nğŸ¯ ì „ì²´ ì‹œìŠ¤í…œ ì¤€ë¹„ë„: {active_count}/{total_count} ({active_count/total_count*100:.1f}%)\")\n",
    "\n",
    "if active_count == total_count:\n",
    "    print(\"\\nğŸ‰ ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤! Streamlit ì•±ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.\")\n",
    "    print(\"   ëª…ë ¹ì–´: python streamlit_run.py\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  ì¼ë¶€ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\")\n",
    "    if not components[\"PostgreSQL (ì •í˜• ë°ì´í„°)\"]:\n",
    "        print(\"   â€¢ docker-compose up -d (PostgreSQL ì‹œì‘)\")\n",
    "        print(\"   â€¢ python setup_project.py (ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”)\")\n",
    "    if not components[\"FAISS Vector DB (ë¹„ì •í˜• ë°ì´í„°)\"]:\n",
    "        print(\"   â€¢ python setup_project.py (ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”)\")\n",
    "    if not components[\"ì›¹ ê²€ìƒ‰ ë„êµ¬ë“¤\"]:\n",
    "        print(\"   â€¢ .env íŒŒì¼ì— TAVILY_API_KEY ì„¤ì •\")\n",
    "    if not components[\"AI ì›Œí¬í”Œë¡œìš° (LangGraph)\"]:\n",
    "        print(\"   â€¢ .env íŒŒì¼ì— UPSTAGE_API_KEY ì„¤ì •\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ë°ëª¨ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "1. **Streamlit ì•± ì‹¤í–‰**: `python streamlit_run.py`\n",
    "2. **AI ìƒë‹´ í…ŒìŠ¤íŠ¸**: ì˜ˆì‹œ ì§ˆë¬¸ë“¤ë¡œ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ í™•ì¸\n",
    "3. **ì›Œí¬í”Œë¡œìš° ì‹œê°í™”**: ìƒˆë¡œ ì¶”ê°€ëœ \"ğŸ”„ ì›Œí¬í”Œë¡œìš°\" íƒ­ì—ì„œ ì‹œê°í™” í™•ì¸\n",
    "4. **ë„êµ¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸**: READMEì˜ 29ê°œ ì˜ˆì‹œ ì§ˆë¬¸ìœ¼ë¡œ ê¸°ëŠ¥ ê²€ì¦\n",
    "\n",
    "### ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ ì§ˆë¬¸ë“¤\n",
    "\n",
    "**ì •í˜• ë°ì´í„° (PostgreSQL):**\n",
    "- \"Python ê°œë°œì 5ë…„ ì´ìƒ ê²½ë ¥ìë¥¼ ì°¾ì•„ì¤˜\"\n",
    "- \"ê°•ë‚¨êµ¬ì— ê±°ì£¼í•˜ëŠ” React ê°œë°œì ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ì—¬ì¤˜\"\n",
    "- \"ì—°ë´‰ 8ì²œë§Œì› ì´ìƒ í¬ë§í•˜ëŠ” ë°±ì—”ë“œ ê°œë°œìê°€ ëª‡ ëª…ì´ì•¼?\"\n",
    "\n",
    "**ë¹„ì •í˜• ë°ì´í„° (FAISS Vector DB):**\n",
    "- \"ìµœê·¼ AI ê°œë°œì ì‹œì¥ íŠ¸ë Œë“œê°€ ì–´ë•Œ?\"\n",
    "- \"í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´ì˜ í‰ê·  ì—°ë´‰ì€ ì–¼ë§ˆë‚˜ ë¼?\"\n",
    "- \"ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ìŠ¤íƒì´ ë­ì•¼?\"\n",
    "\n",
    "**ì›¹ ê²€ìƒ‰ (Tavily):**\n",
    "- \"2024ë…„ ê°œë°œì ì±„ìš© ì‹œì¥ ìµœì‹  ë™í–¥ì„ ì›¹ì—ì„œ ì°¾ì•„ì¤˜\"\n",
    "- \"ë„¤ì´ë²„ì—ì„œ í˜„ì¬ ì±„ìš©ì¤‘ì¸ ê°œë°œì í¬ì§€ì…˜ì´ ë­ê°€ ìˆì–´?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}